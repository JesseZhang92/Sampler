{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Online Batch normalization.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["X7zMeZTJtwbe","5rserNI0kaSn","c9bd4BCoj68W","I52xSdewkmU6","LOSSi4QAs5Ks","dGnVYGI5rgcK"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rpbA6RZfwD1Z","colab_type":"text"},"source":["##**Imports**"]},{"cell_type":"code","metadata":{"id":"LSLEQDl1MDNL","colab_type":"code","colab":{}},"source":["# To use torch 0.4\n","# Also modify loss and model interpolate\n","#!pip uninstall torch -y\n","#!pip uninstall torchvision -y\n","#!pip uninstall fastai -y\n","#!pip install torchvision==0.2.1\n","#!pip install torch==0.4.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVIhqQ7swJq-","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","import os\n","import cv2\n","\n","import random\n","import math\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import collections\n","from collections import OrderedDict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETa8Wj1eajoi","colab_type":"code","colab":{}},"source":["#print(torch.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X7zMeZTJtwbe","colab_type":"text"},"source":["##**Google Drive Dataset Import**"]},{"cell_type":"code","metadata":{"id":"qp2DHzjitVU3","colab_type":"code","outputId":"5eec1a20-cf5b-4d31-e7f7-5d64c0bca9c1","executionInfo":{"status":"ok","timestamp":1567406728304,"user_tz":-120,"elapsed":24339,"user":{"displayName":"Fabio Marchioro","photoUrl":"","userId":"01366493953623100358"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NYB9-fJmvfQY"},"source":["##**Model**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K5DitPjEvfQe","colab":{}},"source":["class SwitchNorm2d(nn.Module):\n","    def __init__(self, num_features, eps=1e-5, momentum=0.1, using_moving_average=True, last_gamma=False):\n","        super(SwitchNorm2d, self).__init__()\n","        self.eps = eps\n","        self.momentum = momentum\n","        self.using_moving_average = using_moving_average\n","        self.last_gamma = last_gamma\n","        self.weight = nn.Parameter(torch.ones(1, num_features, 1, 1))\n","        self.bias = nn.Parameter(torch.zeros(1, num_features, 1, 1))\n","        # determin the weight of the two normalizations to compute the avg mean (will pass through a softmax)\n","        self.mean_weight = nn.Parameter(torch.ones(2))\n","        # determin the weight of the two normalizations to compute the avg variance (will pass through a softmax)\n","        self.var_weight = nn.Parameter(torch.ones(2))\n","        self.register_buffer('running_mean', torch.zeros(1, num_features, 1))\n","        self.register_buffer('running_var', torch.zeros(1, num_features, 1))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.running_mean.zero_()\n","        self.running_var.zero_()\n","        if self.last_gamma:\n","            self.weight.data.fill_(0)\n","        else:\n","            self.weight.data.fill_(1)\n","        self.bias.data.zero_()\n","\n","    def _check_input_dim(self, input):\n","        if input.dim() != 4:\n","            raise ValueError('expected 4D input (got {}D input)'\n","                             .format(input.dim()))\n","\n","    def forward(self, x):\n","        self._check_input_dim(x)\n","        N, C, H, W = x.size()\n","        x = x.view(N, C, -1)\n","        #instancenorm\n","        mean_in = x.mean(-1, keepdim=True)\n","        var_in = x.var(-1, keepdim=True)\n","        #layernorm\n","        mean_ln = mean_in.mean(1, keepdim=True)\n","        temp = var_in + mean_in ** 2\n","        var_ln = temp.mean(1, keepdim=True) - mean_ln ** 2\n","\n","        if self.training:\n","            mean_bn = mean_in.mean(0, keepdim=True)\n","            var_bn = temp.mean(0, keepdim=True) - mean_bn ** 2\n","            if self.using_moving_average:\n","                self.running_mean.mul_(1 - self.momentum)\n","                self.running_mean.add_(self.momentum * mean_bn.data)\n","                self.running_var.mul_(1 - self.momentum)\n","                self.running_var.add_(self.momentum * var_bn.data)\n","            else:\n","                self.running_mean.add_(mean_bn.data)\n","                self.running_var.add_(mean_bn.data ** 2 + var_bn.data)\n","        else:\n","            mean_bn = torch.autograd.Variable(self.running_mean)\n","            var_bn = torch.autograd.Variable(self.running_var)\n","\n","        softmax = nn.Softmax(0)\n","        mean_weight = softmax(self.mean_weight)\n","        var_weight = softmax(self.var_weight)\n","\n","        mean = mean_weight[0] * mean_ln + mean_weight[1] * mean_bn\n","        var = var_weight[0] * var_ln + var_weight[1] * var_bn\n","        \n","        x = (x-mean) / (var+self.eps).sqrt()\n","        x = x.view(N, C, H, W)\n","        return x * self.weight + self.bias\n","      \n","class conv(nn.Module):\n","    def __init__(self, num_in_layers, num_out_layers, kernel_size, stride):\n","        super(conv, self).__init__()\n","        self.kernel_size = kernel_size\n","        self.conv_base = nn.Conv2d(num_in_layers, num_out_layers, kernel_size=kernel_size, stride=stride)\n","        self.normalize = nn.BatchNorm2d(num_out_layers)\n","\n","    def forward(self, x):\n","        p = int(np.floor((self.kernel_size-1)/2))\n","        p2d = (p, p, p, p)\n","        x = self.conv_base(F.pad(x, p2d))\n","        x = self.normalize(x)\n","        return F.elu(x, inplace=True)\n","\n","\n","class convblock(nn.Module):\n","    def __init__(self, num_in_layers, num_out_layers, kernel_size):\n","        super(convblock, self).__init__()\n","        self.conv1 = conv(num_in_layers, num_out_layers, kernel_size, 1)\n","        self.conv2 = conv(num_out_layers, num_out_layers, kernel_size, 2)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        return self.conv2(x)\n","\n","\n","class maxpool(nn.Module):\n","    def __init__(self, kernel_size):\n","        super(maxpool, self).__init__()\n","        self.kernel_size = kernel_size\n","\n","    def forward(self, x):\n","        p = int(np.floor((self.kernel_size-1) / 2))\n","        p2d = (p, p, p, p)\n","        return F.max_pool2d(F.pad(x, p2d), self.kernel_size, stride=2)\n","\n","\n","class resconv(nn.Module):\n","    def __init__(self, num_in_layers, num_out_layers, stride):\n","        super(resconv, self).__init__()\n","        self.num_out_layers = num_out_layers\n","        self.stride = stride\n","        self.conv1 = conv(num_in_layers, num_out_layers, 1, 1)\n","        self.conv2 = conv(num_out_layers, num_out_layers, 3, stride)\n","        self.conv3 = nn.Conv2d(num_out_layers, 4*num_out_layers, kernel_size=1, stride=1)\n","        self.conv4 = nn.Conv2d(num_in_layers, 4*num_out_layers, kernel_size=1, stride=stride)\n","        self.normalize = nn.BatchNorm2d(4*num_out_layers)\n","\n","    def forward(self, x):\n","        # do_proj = x.size()[1] != self.num_out_layers or self.stride == 2\n","        do_proj = True\n","        shortcut = []\n","        x_out = self.conv1(x)\n","        x_out = self.conv2(x_out)\n","        x_out = self.conv3(x_out)\n","        if do_proj:\n","            shortcut = self.conv4(x)\n","        else:\n","            shortcut = x\n","        return F.elu(self.normalize(x_out + shortcut), inplace=True)\n","\n","\n","class resconv_basic(nn.Module):\n","    # for resnet18\n","    def __init__(self, num_in_layers, num_out_layers, stride):\n","        super(resconv_basic, self).__init__()\n","        self.num_out_layers = num_out_layers\n","        self.stride = stride\n","        self.conv1 = conv(num_in_layers, num_out_layers, 3, stride)\n","        self.conv2 = conv(num_out_layers, num_out_layers, 3, 1)\n","        self.conv3 = nn.Conv2d(num_in_layers, num_out_layers, kernel_size=1, stride=stride)\n","        self.normalize = nn.BatchNorm2d(num_out_layers)\n","\n","    def forward(self, x):\n","        #         do_proj = x.size()[1] != self.num_out_layers or self.stride == 2\n","        do_proj = True\n","        shortcut = []\n","        x_out = self.conv1(x)\n","        x_out = self.conv2(x_out)\n","        if do_proj:\n","            shortcut = self.conv3(x)\n","        else:\n","            shortcut = x\n","        return F.elu(self.normalize(x_out + shortcut), inplace=True)\n","\n","\n","def resblock(num_in_layers, num_out_layers, num_blocks, stride):\n","    layers = []\n","    layers.append(resconv(num_in_layers, num_out_layers, stride))\n","    for i in range(1, num_blocks - 1):\n","        layers.append(resconv(4 * num_out_layers, num_out_layers, 1))\n","    layers.append(resconv(4 * num_out_layers, num_out_layers, 1))\n","    return nn.Sequential(*layers)\n","\n","\n","def resblock_basic(num_in_layers, num_out_layers, num_blocks, stride):\n","    layers = []\n","    layers.append(resconv_basic(num_in_layers, num_out_layers, stride))\n","    for i in range(1, num_blocks):\n","        layers.append(resconv_basic(num_out_layers, num_out_layers, 1))\n","    return nn.Sequential(*layers)\n","\n","\n","class upconv(nn.Module):\n","    def __init__(self, num_in_layers, num_out_layers, kernel_size, scale):\n","        super(upconv, self).__init__()\n","        self.scale = scale\n","        self.conv1 = conv(num_in_layers, num_out_layers, kernel_size, 1)\n","\n","    def forward(self, x):\n","        x = nn.functional.interpolate(x, scale_factor=self.scale, mode='bilinear', align_corners=True)\n","        #x = nn.functional.upsample(x, scale_factor=self.scale, mode='bilinear', align_corners=True)\n","        return self.conv1(x)\n","\n","\n","class get_disp(nn.Module):\n","    def __init__(self, num_in_layers):\n","        super(get_disp, self).__init__()\n","        self.conv1 = nn.Conv2d(num_in_layers, 2, kernel_size=3, stride=1)\n","        self.normalize = nn.BatchNorm2d(2)\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def forward(self, x):\n","        p = 1\n","        p2d = (p, p, p, p)\n","        x = self.conv1(F.pad(x, p2d))\n","        x = self.normalize(x)\n","        return 0.3 * self.sigmoid(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzrCdqw2-aOF","colab_type":"code","colab":{}},"source":["class Resnet50_md(nn.Module):\n","    def __init__(self, num_in_layers):\n","        super(Resnet50_md, self).__init__()\n","        # encoder\n","        self.conv1 = conv(num_in_layers, 64, 7, 2)  # H/2  -   64D\n","        self.pool1 = maxpool(3)  # H/4  -   64D\n","        self.conv2 = resblock(64, 64, 3, 2)  # H/8  -  256D\n","        self.conv3 = resblock(256, 128, 4, 2)  # H/16 -  512D\n","        self.conv4 = resblock(512, 256, 6, 2)  # H/32 - 1024D\n","        self.conv5 = resblock(1024, 512, 3, 2)  # H/64 - 2048D\n","\n","        # decoder\n","        self.upconv6 = upconv(2048, 512, 3, 2)\n","        self.iconv6 = conv(1024 + 512, 512, 3, 1)\n","\n","        self.upconv5 = upconv(512, 256, 3, 2)\n","        self.iconv5 = conv(512+256, 256, 3, 1)\n","\n","        self.upconv4 = upconv(256, 128, 3, 2)\n","        self.iconv4 = conv(256+128, 128, 3, 1)\n","        self.disp4_layer = get_disp(128)\n","\n","        self.upconv3 = upconv(128, 64, 3, 2)\n","        self.iconv3 = conv(64+64+2, 64, 3, 1)\n","        self.disp3_layer = get_disp(64)\n","\n","        self.upconv2 = upconv(64, 32, 3, 2)\n","        self.iconv2 = conv(32+64+2, 32, 3, 1)\n","        self.disp2_layer = get_disp(32)\n","\n","        self.upconv1 = upconv(32, 16, 3, 2)\n","        self.iconv1 = conv(16+2, 16, 3, 1)\n","        self.disp1_layer = get_disp(16)\n","\n","        #for m in self.modules():\n","        #    if isinstance(m, nn.Conv2d):\n","        #        nn.init.xavier_uniform_(m.weight)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, 0.01)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def copy_meta_weights(self, meta_weights):\n","        for k, p in self.named_parameters():\n","            if p.requires_grad and k in meta_weights.keys():\n","                p.data = meta_weights[k].data.clone()\n","    \n","    def copy_meta_weights_grad(self, meta_weights):\n","        for k, p in self.named_parameters():\n","            if p.requires_grad and k in meta_weights.keys():\n","                p = meta_weights[k]\n","\n","    def get_learnable_params(self):\n","        params = OrderedDict()\n","        for k, p in self.named_parameters():\n","            if p.requires_grad:\n","                params[k] = p\n","        return params\n","\n","    def forward(self, x, bn_update):\n","        # encoder\n","        x1 = self.conv1(x)\n","        x_pool1 = self.pool1(x1)\n","        x2 = self.conv2(x_pool1)\n","        x3 = self.conv3(x2)\n","        \n","        # test to skip decoder update in the forward pass for the bn update \n","        if bn_update:\n","            return x\n","        \n","        x4 = self.conv4(x3)\n","        x5 = self.conv5(x4)\n","        \n","        # skips\n","        skip1 = x1\n","        skip2 = x_pool1\n","        skip3 = x2\n","        skip4 = x3\n","        skip5 = x4\n","\n","        # decoder\n","        upconv6 = self.upconv6(x5)\n","        concat6 = torch.cat((upconv6, skip5), 1)\n","        iconv6 = self.iconv6(concat6)\n","\n","        upconv5 = self.upconv5(iconv6)\n","        concat5 = torch.cat((upconv5, skip4), 1)\n","        iconv5 = self.iconv5(concat5)\n","\n","        upconv4 = self.upconv4(iconv5)\n","        concat4 = torch.cat((upconv4, skip3), 1)\n","        iconv4 = self.iconv4(concat4)\n","        self.disp4 = self.disp4_layer(iconv4)\n","        self.udisp4 = nn.functional.interpolate(self.disp4, scale_factor=2, mode='bilinear', align_corners=True)\n","        #self.udisp4 = nn.functional.upsample(self.disp4, scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        upconv3 = self.upconv3(iconv4)\n","        concat3 = torch.cat((upconv3, skip2, self.udisp4), 1)\n","        iconv3 = self.iconv3(concat3)\n","        self.disp3 = self.disp3_layer(iconv3)\n","        self.udisp3 = nn.functional.interpolate(self.disp3, scale_factor=2, mode='bilinear', align_corners=True)\n","        #self.udisp3 = nn.functional.upsample(self.disp3, scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        upconv2 = self.upconv2(iconv3)\n","        concat2 = torch.cat((upconv2, skip1, self.udisp3), 1)\n","        iconv2 = self.iconv2(concat2)\n","        self.disp2 = self.disp2_layer(iconv2)\n","        self.udisp2 = nn.functional.interpolate(self.disp2, scale_factor=2, mode='bilinear', align_corners=True)\n","        #self.udisp2 = nn.functional.upsample(self.disp2, scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        upconv1 = self.upconv1(iconv2)\n","        concat1 = torch.cat((upconv1, self.udisp2), 1)\n","        iconv1 = self.iconv1(concat1)\n","        self.disp1 = self.disp1_layer(iconv1)\n","        return self.disp1, self.disp2, self.disp3, self.disp4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zoLR1uMh92VA","colab_type":"code","colab":{}},"source":["class Resnet50_md_switchnorm(nn.Module):\n","    def __init__(self, num_in_layers):\n","        super(Resnet50_md, self).__init__()\n","        # encoder\n","        self.conv1 = conv(num_in_layers, 64, 7, 2)  # H/2  -   64D\n","        self.pool1 = maxpool(3)  # H/4  -   64D\n","        self.conv2 = resblock(64, 64, 3, 2)  # H/8  -  256D\n","        self.conv3 = resblock(256, 128, 4, 2)  # H/16 -  512D\n","        self.conv4 = resblock(512, 256, 6, 2)  # H/32 - 1024D\n","        self.conv5 = resblock(1024, 512, 3, 2)  # H/64 - 2048D\n","\n","        # decoder\n","        self.upconv6 = upconv(2048, 512, 3, 2)\n","        self.iconv6 = conv(1024 + 512, 512, 3, 1)\n","\n","        self.upconv5 = upconv(512, 256, 3, 2)\n","        self.iconv5 = conv(512+256, 256, 3, 1)\n","\n","        self.upconv4 = upconv(256, 128, 3, 2)\n","        self.iconv4 = conv(256+128, 128, 3, 1)\n","        self.disp4_layer = get_disp(128)\n","\n","        self.upconv3 = upconv(128, 64, 3, 2)\n","        self.iconv3 = conv(64+64+2, 64, 3, 1)\n","        self.disp3_layer = get_disp(64)\n","\n","        self.upconv2 = upconv(64, 32, 3, 2)\n","        self.iconv2 = conv(32+64+2, 32, 3, 1)\n","        self.disp2_layer = get_disp(32)\n","\n","        self.upconv1 = upconv(32, 16, 3, 2)\n","        self.iconv1 = conv(16+2, 16, 3, 1)\n","        self.disp1_layer = get_disp(16)\n","\n","        #for m in self.modules():\n","        #    if isinstance(m, nn.Conv2d):\n","        #        nn.init.xavier_uniform_(m.weight)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, 0.01)\n","            elif isinstance(m, SwitchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def copy_meta_weights(self, meta_weights):\n","        for k, p in self.named_parameters():\n","            if p.requires_grad and k in meta_weights.keys():\n","                p.data = meta_weights[k].data.clone()\n","    \n","    def copy_meta_weights_grad(self, meta_weights):\n","        for k, p in self.named_parameters():\n","            if p.requires_grad and k in meta_weights.keys():\n","                p = meta_weights[k]\n","\n","    def get_learnable_params(self):\n","        params = OrderedDict()\n","        for k, p in self.named_parameters():\n","            if p.requires_grad:\n","                params[k] = p\n","        return params\n","\n","    def forward(self, x, bn_update):\n","        # encoder\n","        x1 = self.conv1(x)\n","        x_pool1 = self.pool1(x1)\n","        x2 = self.conv2(x_pool1)\n","        x3 = self.conv3(x2)\n","        x4 = self.conv4(x3)\n","        x5 = self.conv5(x4)\n","\n","        # test to skip decoder update in the forward pass for the bn update \n","        if bn_update:\n","            return x\n","\n","        # skips\n","        skip1 = x1\n","        skip2 = x_pool1\n","        skip3 = x2\n","        skip4 = x3\n","        skip5 = x4\n","\n","        # decoder\n","        upconv6 = self.upconv6(x5)\n","        concat6 = torch.cat((upconv6, skip5), 1)\n","        iconv6 = self.iconv6(concat6)\n","\n","        upconv5 = self.upconv5(iconv6)\n","        concat5 = torch.cat((upconv5, skip4), 1)\n","        iconv5 = self.iconv5(concat5)\n","\n","        upconv4 = self.upconv4(iconv5)\n","        concat4 = torch.cat((upconv4, skip3), 1)\n","        iconv4 = self.iconv4(concat4)\n","        self.disp4 = self.disp4_layer(iconv4)\n","        self.udisp4 = nn.functional.interpolate(self.disp4, scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        upconv3 = self.upconv3(iconv4)\n","        concat3 = torch.cat((upconv3, skip2, self.udisp4), 1)\n","        iconv3 = self.iconv3(concat3)\n","        self.disp3 = self.disp3_layer(iconv3)\n","        self.udisp3 = nn.functional.interpolate(self.disp3, scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        upconv2 = self.upconv2(iconv3)\n","        concat2 = torch.cat((upconv2, skip1, self.udisp3), 1)\n","        iconv2 = self.iconv2(concat2)\n","        self.disp2 = self.disp2_layer(iconv2)\n","        self.udisp2 = nn.functional.interpolate(self.disp2, scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        upconv1 = self.upconv1(iconv2)\n","        concat1 = torch.cat((upconv1, self.udisp2), 1)\n","        iconv1 = self.iconv1(concat1)\n","        self.disp1 = self.disp1_layer(iconv1)\n","        return self.disp1, self.disp2, self.disp3, self.disp4"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rserNI0kaSn","colab_type":"text"},"source":["##**Loss**"]},{"cell_type":"code","metadata":{"id":"SD9r53vo5AFB","colab_type":"code","colab":{}},"source":["class MonodepthLoss(nn.modules.Module):\n","    def __init__(self, n=4, SSIM_w=0.85, disp_gradient_w=1.0, lr_w=1.0):\n","        super(MonodepthLoss, self).__init__()\n","        self.SSIM_w = SSIM_w\n","        self.disp_gradient_w = disp_gradient_w\n","        self.lr_w = lr_w\n","        self.n = n\n","\n","    def scale_pyramid(self, img, num_scales):\n","        scaled_imgs = [img]\n","        s = img.size()\n","        h = s[2]\n","        w = s[3]\n","        for i in range(num_scales - 1):\n","            ratio = 2 ** (i + 1)\n","            nh = h // ratio\n","            nw = w // ratio\n","            scaled_imgs.append(nn.functional.interpolate(img, size=[nh, nw], mode='bilinear', align_corners=True))\n","            #scaled_imgs.append(nn.functional.upsample(img, size=[nh, nw], mode='bilinear', align_corners=True))\n","        return scaled_imgs\n","\n","    def gradient_x(self, img):\n","        # Pad input to keep output size consistent\n","        img = F.pad(img, (0, 1, 0, 0), mode='replicate')\n","        gx = img[:, :, :, :-1] - img[:, :, :, 1:]  # NCHW\n","        return gx\n","\n","    def gradient_y(self, img):\n","        # Pad input to keep output size consistent\n","        img = F.pad(img, (0, 0, 0, 1), mode='replicate')\n","        gy = img[:, :, :-1, :] - img[:, :, 1:, :]  # NCHW\n","        return gy\n","\n","    def apply_disparity(self, img, disp):\n","        batch_size, _, height, width = img.size()\n","\n","        # Original coordinates of pixels\n","        x_base = torch.linspace(0, 1, width).repeat(batch_size, height, 1).type_as(img)\n","        y_base = torch.linspace(0, 1, height).repeat(batch_size, width, 1).transpose(1, 2).type_as(img)\n","\n","        # Apply shift in X direction\n","        x_shifts = disp[:, 0, :, :]  # Disparity is passed in NCHW format with 1 channel\n","        flow_field = torch.stack((x_base + x_shifts, y_base), dim=3)\n","        # In grid_sample coordinates are assumed to be between -1 and 1\n","        output = F.grid_sample(img, 2*flow_field - 1, mode='bilinear', padding_mode='zeros')\n","\n","        return output\n","\n","    def generate_image_left(self, img, disp):\n","        return self.apply_disparity(img, -disp)\n","\n","    def generate_image_right(self, img, disp):\n","        return self.apply_disparity(img, disp)\n","\n","    def SSIM(self, x, y):\n","        C1 = 0.01 ** 2\n","        C2 = 0.03 ** 2\n","\n","        mu_x = nn.AvgPool2d(3, 1)(x)\n","        mu_y = nn.AvgPool2d(3, 1)(y)\n","        mu_x_mu_y = mu_x * mu_y\n","        mu_x_sq = mu_x.pow(2)\n","        mu_y_sq = mu_y.pow(2)\n","\n","        sigma_x = nn.AvgPool2d(3, 1)(x * x) - mu_x_sq\n","        sigma_y = nn.AvgPool2d(3, 1)(y * y) - mu_y_sq\n","        sigma_xy = nn.AvgPool2d(3, 1)(x * y) - mu_x_mu_y\n","\n","        SSIM_n = (2 * mu_x_mu_y + C1) * (2 * sigma_xy + C2)\n","        SSIM_d = (mu_x_sq + mu_y_sq + C1) * (sigma_x + sigma_y + C2)\n","        SSIM = SSIM_n / SSIM_d\n","\n","        return torch.clamp((1 - SSIM) / 2, 0, 1)\n","\n","    def disp_smoothness(self, disp, pyramid):\n","        disp_gradients_x = [self.gradient_x(d) for d in disp]\n","        disp_gradients_y = [self.gradient_y(d) for d in disp]\n","\n","        image_gradients_x = [self.gradient_x(img) for img in pyramid]\n","        image_gradients_y = [self.gradient_y(img) for img in pyramid]\n","\n","        weights_x = [torch.exp(-torch.mean(torch.abs(g), 1, keepdim=True)) for g in image_gradients_x]\n","        weights_y = [torch.exp(-torch.mean(torch.abs(g), 1, keepdim=True)) for g in image_gradients_y]\n","\n","        smoothness_x = [disp_gradients_x[i] * weights_x[i] for i in range(self.n)]\n","        smoothness_y = [disp_gradients_y[i] * weights_y[i] for i in range(self.n)]\n","\n","        return [torch.abs(smoothness_x[i]) + torch.abs(smoothness_y[i]) for i in range(self.n)]\n","\n","    def forward(self, input, target):\n","        '''\n","        Args:\n","            input [disp1, disp2, disp3, disp4]\n","            target [left, right]\n","\n","        Return:\n","            (float): The loss\n","        '''\n","        left, right = target\n","        left_pyramid = self.scale_pyramid(left, self.n)\n","        right_pyramid = self.scale_pyramid(right, self.n)\n","\n","        # Prepare disparities\n","        disp_left_est = [d[:, 0, :, :].unsqueeze(1) for d in input]\n","        disp_right_est = [d[:, 1, :, :].unsqueeze(1) for d in input]\n","\n","        self.disp_left_est = disp_left_est\n","        self.disp_right_est = disp_right_est\n","        # Generate images\n","        left_est = [self.generate_image_left(right_pyramid[i], disp_left_est[i]) for i in range(self.n)]\n","        right_est = [self.generate_image_right(left_pyramid[i], disp_right_est[i]) for i in range(self.n)]\n","        self.left_est = left_est\n","        self.right_est = right_est\n","\n","        # L-R Consistency\n","        right_left_disp = [self.generate_image_left(disp_right_est[i], disp_left_est[i]) for i in range(self.n)]\n","        left_right_disp = [self.generate_image_right(disp_left_est[i], disp_right_est[i]) for i in range(self.n)]\n","\n","        # Disparities smoothness\n","        disp_left_smoothness = self.disp_smoothness(disp_left_est, left_pyramid)\n","        disp_right_smoothness = self.disp_smoothness(disp_right_est, right_pyramid)\n","\n","        # L1\n","        l1_left = [torch.mean(torch.abs(left_est[i] - left_pyramid[i])) for i in range(self.n)]\n","        l1_right = [torch.mean(torch.abs(right_est[i] - right_pyramid[i])) for i in range(self.n)]\n","\n","        # SSIM\n","        ssim_left = [torch.mean(self.SSIM(left_est[i], left_pyramid[i])) for i in range(self.n)]\n","        ssim_right = [torch.mean(self.SSIM(right_est[i], right_pyramid[i])) for i in range(self.n)]\n","\n","        image_loss_left = [self.SSIM_w * ssim_left[i] + (1 - self.SSIM_w) * l1_left[i] for i in range(self.n)]\n","        image_loss_right = [self.SSIM_w * ssim_right[i] + (1 - self.SSIM_w) * l1_right[i] for i in range(self.n)]\n","        image_loss = sum(image_loss_left + image_loss_right)\n","\n","        # L-R Consistency\n","        lr_left_loss = [torch.mean(torch.abs(right_left_disp[i] - disp_left_est[i])) for i in range(self.n)]\n","        lr_right_loss = [torch.mean(torch.abs(left_right_disp[i] - disp_right_est[i])) for i in range(self.n)]\n","        lr_loss = sum(lr_left_loss + lr_right_loss)\n","\n","        # Disparities smoothness\n","        disp_left_loss = [torch.mean(torch.abs(disp_left_smoothness[i])) / 2 ** i for i in range(self.n)]\n","        disp_right_loss = [torch.mean(torch.abs(disp_right_smoothness[i])) / 2 ** i for i in range(self.n)]\n","        disp_gradient_loss = sum(disp_left_loss + disp_right_loss)\n","\n","        loss = image_loss + self.disp_gradient_w * disp_gradient_loss + self.lr_w * lr_loss\n","        self.image_loss = image_loss\n","        self.disp_gradient_loss = disp_gradient_loss\n","        self.lr_loss = lr_loss\n","        return loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c9bd4BCoj68W","colab_type":"text"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"t17IDtkv5Hy-","colab_type":"code","colab":{}},"source":["def image_transforms(transformations=None,  size=(256, 512)):\n","        return transforms.Compose([ResizeImage(size=size), ToTensor()])\n","\n","\n","class ResizeImage(object):\n","    def __init__(self, size=(256, 512)):\n","        self.transform = transforms.Resize(size)\n","\n","    def __call__(self, sample):\n","        left_image = sample['left_image']\n","        right_image = sample['right_image']\n","        new_right_image = self.transform(right_image)\n","        new_left_image = self.transform(left_image)\n","        sample = {'left_image': new_left_image, 'right_image': new_right_image}\n","        return sample\n","\n","\n","class ToTensor(object):\n","    def __init__(self):\n","        self.transform = transforms.ToTensor()\n","\n","    def __call__(self, sample):\n","        left_image = sample['left_image']\n","        right_image = sample['right_image']\n","        new_right_image = self.transform(right_image)\n","        new_left_image = self.transform(left_image)\n","        sample = {'left_image': new_left_image, 'right_image': new_right_image}\n","        return sample\n","\n","\n","def to_device(input, device):\n","    if torch.is_tensor(input):\n","        return input.to(device=device)\n","    elif isinstance(input, str):\n","        return input\n","    elif isinstance(input, collections.Mapping):\n","        return {k: to_device(sample, device=device) for k, sample in input.items()}\n","    elif isinstance(input, collections.Sequence):\n","        return [to_device(sample, device=device) for sample in input]\n","    else:\n","        raise TypeError('Input must contain tensor, dict or list, found {type(input)}')\n","\n","        \n","def prepare_dataloader(drive, shuffle, batch_size, size, num_workers):\n","    data_transform = image_transforms(size = size)\n","    \n","    frames_list = []\n","    for frame in os.listdir(drive + '/image_02/data/'): # add all frames in a sequence\n","        frames_list.append(drive + '/image_02/data/' + frame + ',' + drive + '/image_03/data/' + frame)\n","            \n","    dataset = KittiLoader(frames_list, transform = data_transform) # define dataset\n","    n_img = len(dataset) # get images number\n","    print('The drive contains', n_img, 'frames')\n","    loader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle, num_workers = num_workers, pin_memory = True) # create loader\n","    return n_img, loader\n","\n","\n","class KittiLoader(Dataset):\n","    def __init__(self, lines, transform=None):\n","        \n","        #with open(root_dir + '.txt') as file:\n","        #    lines = file.readlines()\n","        self.transform = transform\n","        self.lines = lines\n","\n","    def __len__(self):\n","        return len(self.lines)\n","\n","    def __getitem__(self, idx):\n","        left_image = Image.open(self.lines[idx].split(',')[0]) # get the left image [0]\n","        right_image = Image.open(self.lines[idx].split(',')[1]) # get the right image [1]\n","        sample = {'left_image': left_image, 'right_image': right_image}\n","        if self.transform: # apply a transformation if defined\n","            sample = self.transform(sample)\n","        return sample\n","\n","\n","def set_dataset_dict(test_dict):\n","    # read eigen_test and create a dictionary of drives and the list of frames to be evaluated for each one\n","    with open(test_split) as ts:\n","        for line in ts:\n","            frame = line.split()[0]\n","            if frame.split('/')[1] not in test_dict.keys():\n","                test_dict[frame.split('/')[1]] = []\n","            test_dict[frame.split('/')[1]].append(frame.split('/')[4])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I52xSdewkmU6","colab_type":"text"},"source":["##**Eval Utils**"]},{"cell_type":"code","metadata":{"id":"Y5NA8LZV5UOV","colab_type":"code","colab":{}},"source":["def compute_errors(gt, pred):\n","    thresh = np.maximum((gt / pred), (pred / gt))\n","    a1 = (thresh < 1.25   ).mean()\n","    a2 = (thresh < 1.25 ** 2).mean()\n","    a3 = (thresh < 1.25 ** 3).mean()\n","\n","    rmse = (gt - pred) ** 2\n","    rmse = np.sqrt(rmse.mean())\n","\n","    d1 = np.mean(np.abs(gt - pred))\n","\n","    rmse_log = (np.log(gt) - np.log(pred)) ** 2\n","    rmse_log = np.sqrt(rmse_log.mean())\n","\n","    abs_rel = np.mean(np.abs(gt - pred) / gt)\n","\n","    sq_rel = np.mean(((gt - pred)**2) / gt)\n","\n","    return abs_rel, sq_rel, rmse, rmse_log, d1, a1, a2, a3\n","\n","\n","def read_calib_file(path):\n","    # taken from https://github.com/hunse/kitti\n","    float_chars = set('0123456789.e+- ')\n","    data = {}\n","    with open(path, 'r') as f:\n","        for line in f.readlines():\n","            key, value = line.split(':', 1)\n","            value = value.strip()\n","            data[key] = value\n","            if float_chars.issuperset(value):\n","                # try to cast to float array\n","                try:\n","                    data[key] = np.array(list(map(float, value.split(' '))))\n","                except ValueError:\n","                    # casting error: data[key] already eq. value, so pass\n","                    pass\n","\n","    return data\n","\n","\n","def get_focal_length_baseline(calib_dir, cam):\n","    cam2cam = read_calib_file(calib_dir + 'calib_cam_to_cam.txt')\n","    P2_rect = cam2cam['P_rect_02'].reshape(3,4)\n","    P3_rect = cam2cam['P_rect_03'].reshape(3,4)\n","\n","    # cam 2 is left of camera 0  -6cm\n","    # cam 3 is to the right  +54cm\n","    b2 = P2_rect[0,3] / -P2_rect[0,0]\n","    b3 = P3_rect[0,3] / -P3_rect[0,0]\n","    baseline = b3-b2\n","\n","    if cam==2:\n","        focal_length = P2_rect[0,0]\n","    elif cam==3:\n","        focal_length = P3_rect[0,0]\n","\n","    return focal_length, baseline\n","  \n","def eval_frame_disps(statistics, frame, kitti_path, drive, loss, disps, frame_idx):\n","    disp = disps[0][frame_idx, 0, :, :].unsqueeze(1) # (1,2,256,512) -> (1,256,512)\n","    disp = disp.squeeze().cpu().detach().numpy() # (1,256,512) -> (256,512)\n","    gt_depth = cv2.imread(kitti_path + drive.rsplit('_', 3)[0] + '/' + drive + '/' + gt_path + '/' + frame, cv2.IMREAD_UNCHANGED) # get groundtruth image (only left one)\n","    gt_depth = np.array(gt_depth, dtype=np.float32)\n","    gt_depth = gt_depth/256 # divide for 256 ?????????????????????????\n","    im_size = gt_depth.shape[:2] # (375, 1242)\n","    disp_pred = cv2.resize(disp, (im_size[1], im_size[0]), interpolation = cv2.INTER_LINEAR) # resize translated images to the groundtruth image size\n","    disp_pred = disp_pred * disp_pred.shape[1] # multiply for a scalar (1242) ????????????????????????????????\n","    camera_id = 2\n","    focal_length, baseline = get_focal_length_baseline(kitti_path + drive.rsplit('_', 3)[0] + '/', camera_id)\n","    depth_pred = (baseline * focal_length) / disp_pred # predicted depth\n","    depth_pred[np.isinf(depth_pred)] = 0 # set infinite values of prediction to 0\n","    min_depth = 1e-3\n","    max_depth = 50\n","    mask = np.logical_and(gt_depth > min_depth, gt_depth < max_depth) # create a mask to restrict the range of predicted depths to [0.001, 50]\n","    gt_height, gt_width = gt_depth.shape # eigen crop\n","    crop = np.array([0.3324324 * gt_height, 0.91351351 * gt_height, 0.0359477 * gt_width, 0.96405229 * gt_width]).astype(np.int32) # crop image with specific values ??????????\n","    crop_mask = np.zeros(mask.shape)\n","    crop_mask[crop[0]:crop[1],crop[2]:crop[3]] = 1\n","    mask = np.logical_and(mask, crop_mask) # build a matrix based on the mask\n","    abs_rel, sq_rel, rmse, log_rmse, d1, a1, a2, a3 = compute_errors(gt_depth[mask], depth_pred[mask]) # compute statistics with dept_pred and groundtruth using the mask\n","    # add statistics to respective vectors\n","    statistics[0]['loss'].append(loss.item()) # loss\n","    statistics[0]['abs_rel'].append(abs_rel) # relative absolute error\n","    statistics[0]['sq_rel'].append(sq_rel) # squared relative absolute error\n","    statistics[0]['rmse'].append(rmse) # root mean square error\n","    statistics[0]['log_rmse'].append(log_rmse) # log rmse\n","    statistics[0]['d1'].append(d1) # absolute error\n","    statistics[0]['a1'].append(a1) # diff<1.25\n","    statistics[0]['a2'].append(a2) # diff<1.25**2\n","    statistics[0]['a3'].append(a3) # diff<1.25**3\n","    statistics[1] += 1 # number of frames evaluated\n","      \n","    if show_logs:\n","        print('│    {:^4d}       {:^6.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}    {:^6.4f}    {:^6.4f}    {:^6.4f}  │'\n","               .format(int(frame.split('.')[0]), loss.item(), abs_rel, sq_rel, rmse, log_rmse, d1, a1, a2, a3))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOSSi4QAs5Ks","colab_type":"text"},"source":["##**Logs and Graphs**"]},{"cell_type":"code","metadata":{"id":"VuoI8uoHtBDA","colab_type":"code","colab":{}},"source":["def logs_and_graphs(statistics, drive):\n","    n = math.ceil(statistics[1]/5)\n","    if show_avg_logs:\n","        print('│  Averages     {:^6.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}    {:^6.4f}    {:^6.4f}    {:^6.4f}  │'\n","              .format(sum(statistics[0]['loss'])/statistics[1],\n","                      sum(statistics[0]['abs_rel'])/statistics[1],\n","                      sum(statistics[0]['sq_rel'])/statistics[1],\n","                      sum(statistics[0]['rmse'])/statistics[1],\n","                      sum(statistics[0]['log_rmse'])/statistics[1],\n","                      sum(statistics[0]['d1'])/statistics[1],\n","                      sum(statistics[0]['a1'])/statistics[1],\n","                      sum(statistics[0]['a2'])/statistics[1],\n","                      sum(statistics[0]['a3'])/statistics[1]))\n","        print('│  Last 20%     {:^6.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}     {:^7.4f}    {:^6.4f}    {:^6.4f}    {:^6.4f}  │'\n","              .format(sum(statistics[0]['loss'][-n:])/n,\n","                      sum(statistics[0]['abs_rel'][-n:])/n,\n","                      sum(statistics[0]['sq_rel'][-n:])/n,\n","                      sum(statistics[0]['rmse'][-n:])/n,\n","                      sum(statistics[0]['log_rmse'][-n:])/n,\n","                      sum(statistics[0]['d1'][-n:])/n,\n","                      sum(statistics[0]['a1'][-n:])/n,\n","                      sum(statistics[0]['a2'][-n:])/n,\n","                      sum(statistics[0]['a3'][-n:])/n))\n","        print('└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘')\n","            \n","    if save_logs or save_graphs:\n","        new_folder = 'results/' + drive.rsplit('_', 3)[0] + '/' + drive + '/'\n","        if not os.path.exists(new_folder):\n","            os.makedirs(new_folder)\n","\n","    if save_logs:\n","        # saves stats into log files\n","        with open(new_folder + 'log_loss.txt', 'w') as log:\n","            for stat in statistics[0]['loss']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_abs_rel.txt', 'w') as log:\n","            for stat in statistics[0]['abs_rel']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_sq_rel.txt', 'w') as log:\n","            for stat in statistics[0]['sq_rel']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_rmse.txt', 'w') as log:\n","            for stat in statistics[0]['rmse']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_log_rmse.txt', 'w') as log:\n","            for stat in statistics[0]['log_rmse']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_d1.txt', 'w') as log:\n","            for stat in statistics[0]['d1']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_a1.txt', 'w') as log:\n","            for stat in statistics[0]['a1']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_a2.txt', 'w') as log:\n","            for stat in statistics[0]['a2']:\n","                log.write('%.4f\\n' % stat)\n","        with open(new_folder + 'log_a3.txt', 'w') as log:\n","            for stat in statistics[0]['a3']:\n","                log.write('%.4f\\n' % stat)\n","    \n","    if show_graphs or save_graphs:\n","        graphs, subplt = plt.subplots(3, 3, figsize = (15, 15)) # 9 graphs, one for each statistic\n","        for (i, stat) in enumerate(statistics[0]):\n","            subplt[math.floor(i/3), i%3].plot(statistics[0][stat])\n","            subplt[math.floor(i/3), i%3].set_title(stat, color='white', fontsize=20)\n","            subplt[math.floor(i/3), i%3].grid(True)\n","            subplt[math.floor(i/3), i%3].tick_params(colors='white')\n","            subplt[math.floor(i/3), i%3].patch.set_facecolor('xkcd:very pale blue')\n","        if (save_graphs):\n","            plt.savefig(new_folder + 'graphs.png', facecolor = graphs.get_facecolor(), edgecolor='none')\n","        if (show_graphs):\n","            plt.show()\n","        plt.close()\n","    \n","    if show_each_sheet_string:\n","        print('=SPLIT(\"{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f}\", \",\")\\n'\n","               .format(sum(statistics[0]['rmse'])/statistics[1],\n","                       sum(statistics[0]['abs_rel'])/statistics[1],\n","                       sum(statistics[0]['sq_rel'])/statistics[1],\n","                       sum(statistics[0]['log_rmse'])/statistics[1],\n","                       sum(statistics[0]['rmse'][-n:])/n,\n","                       sum(statistics[0]['abs_rel'][-n:])/n,\n","                       sum(statistics[0]['sq_rel'][-n:])/n,\n","                       sum(statistics[0]['log_rmse'][-n:])/n))\n","    \n","    return ('=SPLIT(\"{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f},{:07.4f}\", \",\")\\n'\n","            .format(sum(statistics[0]['rmse'])/statistics[1],\n","                    sum(statistics[0]['abs_rel'])/statistics[1],\n","                    sum(statistics[0]['sq_rel'])/statistics[1],\n","                    sum(statistics[0]['log_rmse'])/statistics[1],\n","                    sum(statistics[0]['rmse'][-n:])/n,\n","                    sum(statistics[0]['abs_rel'][-n:])/n,\n","                    sum(statistics[0]['sq_rel'][-n:])/n,\n","                    sum(statistics[0]['log_rmse'][-n:])/n))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pEZ00aLCkRTr","colab_type":"text"},"source":["##**Main**"]},{"cell_type":"code","metadata":{"id":"4Fl-VfCkNba_","colab_type":"code","colab":{}},"source":["# used to test a specific set of drives, remove the others form the dictionary\n","def edit_dataset_dict(dataset_dict):\n","    '''\n","    del dataset_dict['2011_09_26_drive_0002_sync'] # 77\n","    del dataset_dict['2011_09_26_drive_0009_sync'] # 447\n","    del dataset_dict['2011_09_26_drive_0013_sync'] # 144\n","    del dataset_dict['2011_09_26_drive_0020_sync'] # 86\n","    del dataset_dict['2011_09_26_drive_0023_sync'] # 474\n","    del dataset_dict['2011_09_26_drive_0027_sync'] # 188\n","    del dataset_dict['2011_09_26_drive_0029_sync'] # 430\n","    del dataset_dict['2011_09_26_drive_0036_sync'] # 803\n","    del dataset_dict['2011_09_26_drive_0046_sync'] # 125\n","    del dataset_dict['2011_09_26_drive_0048_sync'] # 22\n","    del dataset_dict['2011_09_26_drive_0052_sync'] # 78\n","    del dataset_dict['2011_09_26_drive_0056_sync'] # 294\n","    del dataset_dict['2011_09_26_drive_0059_sync'] # 373\n","    del dataset_dict['2011_09_26_drive_0064_sync'] # 570\n","    del dataset_dict['2011_09_26_drive_0084_sync'] # 383\n","    del dataset_dict['2011_09_26_drive_0086_sync'] # 706\n","    del dataset_dict['2011_09_26_drive_0093_sync'] # 433\n","    del dataset_dict['2011_09_26_drive_0096_sync'] # 475\n","    del dataset_dict['2011_09_26_drive_0101_sync'] # 936\n","    del dataset_dict['2011_09_26_drive_0106_sync'] # 227\n","    del dataset_dict['2011_09_26_drive_0117_sync'] # 660\n","    del dataset_dict['2011_09_28_drive_0002_sync'] # 376\n","    del dataset_dict['2011_09_29_drive_0071_sync'] # 1059\n","    del dataset_dict['2011_09_30_drive_0016_sync'] # 279\n","    del dataset_dict['2011_09_30_drive_0018_sync'] # 2762\n","    del dataset_dict['2011_09_30_drive_0027_sync'] # 1106\n","    del dataset_dict['2011_10_03_drive_0027_sync'] # 4544\n","    del dataset_dict['2011_10_03_drive_0047_sync'] # 837\n","    '''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7plUHsOH46Wu","colab_type":"code","colab":{}},"source":["# parameters definition\n","#pre_trained_model = 'drive/My Drive/pretrained_model_197_mine.pth' # path of the pretrained model\n","#pre_trained_model = 'drive/My Drive/pretrained_model_119_mine.pth' # path of the pretrained model\n","pre_trained_model = 'drive/My Drive/pretrained_model_zhenyu.pth' # path of the pretrained model\n","#pre_trained_model = 'drive/My Drive/pretrained_model_switchnorm_124.pth' # path of the pretrained model\n","kitti_path = 'drive/My Drive/Kitti/' # path of the dataset\n","test_split = kitti_path + 'eigen_test.txt' # list of fraes to evaluate\n","gt_path = 'proj_depth/groundtruth/image_02' # path of the groundtruth images, used during evaluation\n","input_height = 256\n","input_width = 512\n","input_channels = 3*2 # rbg * two images\n","model = 'resnet50_md'\n","#model = 'resnet50_md_switchorm'\n","batch_size = 1\n","shuffle = False\n","learning_rate = 1e-4\n","bn_momentum = 0.03 # momentum for the batch normalization layers\n","device = 'cuda:0'\n","num_workers = 0\n","\n","# 0 - NAIVE\n","# 1 - Meta-Learning\n","# 2 - OFDA\n","# 3 - OMLA\n","used_method = 2\n","\n","show_logs = True # shows logs of each frame\n","show_avg_logs = True # shows logs of average score of each drive\n","show_graphs = True # shows 9 graphs of the statistics of the drive\n","show_each_sheet_string = True # show a string to paste on google sheets to copy results for an individual drive\n","show_sheet_string = True # show a string to paste on google sheets to copy results for all drives\n","save_logs = True # save logs on results/<drive_day>/<drive>/log_<stat_name>.txt\n","save_graphs = True # save the graphs in results/<drive_day>/<drive>/graphs.png\n","\n","\n","class Model:\n","\n","    def __init__(self):\n","        # Set up model\n","        self.device = device\n","        self.model = Resnet50_md(input_channels)\n","        self.model = self.model.to(self.device)\n","\n","        self.loss_function = MonodepthLoss(n = 4, SSIM_w = 0.85, disp_gradient_w = 0.1, lr_w = 1).to(self.device)\n","        self.optimizer = optim.Adam(self.model.parameters(), lr = learning_rate)\n","        \n","        self.input_height = input_height\n","        self.input_width = input_width\n","        self.dataset_dict = {}\n","        self.transform = transforms.Compose([transforms.Resize((input_height, input_width)), transforms.ToTensor()])\n","                \n","        self.statistics = [{'loss': [], 'rmse':[], 'log_rmse':[], 'abs_rel':[], 'sq_rel':[], 'd1':[], 'a1':[], 'a2':[], 'a3':[]}, 0]\n","        \n","        if 'cuda' in self.device:\n","            torch.cuda.synchronize()\n","    \n","    def perform_domain_adaptation(self):\n","        if used_method != 0 and used_method != 1 and used_method != 2 and used_method != 3:\n","            print('Invalid method selected')\n","        else:\n","            set_dataset_dict(self.dataset_dict)\n","            edit_dataset_dict(self.dataset_dict)\n","            sheet_string = ''\n","            \n","            if used_method == 0:\n","                print('Currently using Onine Naive method')\n","            elif used_method == 1:\n","                print('Currently using Meta Learning method')\n","            elif used_method == 2:\n","                print('Currently using OFDA method')\n","            elif used_method == 3:\n","                print('Currently using OMLA method')\n","\n","            print('Starting with learning rate =', learning_rate)\n","            \n","            for module in self.model.modules():\n","                if isinstance(module, nn.BatchNorm2d):\n","                    module.momentum = bn_momentum # set the momentum of a batch normalization layer to the desired value\n","\n","            print('Momentum of BN Layers =', bn_momentum)\n","            \n","            for drive in self.dataset_dict.keys():\n","                print('═══════════════════════════════════════ drive : ' + drive + ' ════════════════════════════════════════')\n","                print()\n","\n","                drive_frames = os.listdir(kitti_path + drive.rsplit('_', 3)[0] + '/' + drive + '/image_02/data/')\n","                \n","                if shuffle:\n","                    random.shuffle(drive_frames)\n","                    for kf in self.dataset_dict[drive]:\n","                        drive_frames[drive_frames.index(kf)], drive_frames[int(kf.split('.')[0])] = drive_frames[int(kf.split('.')[0])], drive_frames[drive_frames.index(kf)]\n","                else:\n","                    drive_frames.sort()\n","                \n","                self.statistics = [{'loss': [], 'rmse':[], 'log_rmse':[], 'abs_rel':[], 'sq_rel':[], 'd1':[], 'a1':[], 'a2':[], 'a3':[]}, 0]\n","                print('Loading trained network ' + pre_trained_model)\n","                print('This drive contains ' + str(len(drive_frames)) + ' frames')\n","                \n","                # OLDER VERSION OF TORCH/TORCHVISION\n","                #model_dict = self.model.state_dict()\n","                #pretrained_dict = {k: v for k, v in torch.load(pre_trained_model).items() if k in model_dict}\n","                # 2. overwrite entries in the existing state dict\n","                #model_dict.update(pretrained_dict) \n","                # 3. load the new state dict\n","                #self.model.load_state_dict(pretrained_dict)\n","                self.model.load_state_dict(torch.load(pre_trained_model))\n","      \n","                if show_logs or show_avg_logs:\n","                    print()\n","                    print('┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐')\n","                    print('│    Frame       Loss      Abs_rel      Sq_rel      Rmse      Rmse_Log       d1         a1        a2        a3    │')\n","                    print('├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤')\n","                    \n","                for i in range(0, len(drive_frames), batch_size):\n","                    # prepare batch\n","                    left_imgs = []\n","                    right_imgs = []\n","                    for frame in drive_frames[i:i+batch_size]:\n","                        left_imgs.append(self.transform(Image.open(kitti_path + drive.rsplit('_', 3)[0] + '/' + drive + '/image_02/data/' + frame)))\n","                        right_imgs.append(self.transform(Image.open(kitti_path + drive.rsplit('_', 3)[0] + '/' + drive + '/image_03/data/' + frame)))\n","                    left = to_device(torch.stack(left_imgs, dim = 0), device)\n","                    right = to_device(torch.stack(right_imgs, dim = 0), device)\n","                    img_pair = torch.cat((left, right), 1)\n","                    self.optimizer.zero_grad()\n","                    \n","                    # 0 : Naive - No BN statistics update and fixed learning rate (no global statistics)\n","                    # 1 : Meta Learning - No BN statistics update and meta learning rate\n","                    # 2 : OFDA - BN statistics update and fixed learning rate\n","                    # 3 : OMLA - BN statistics update and meta learning rate\n","\n","                    # BN statistics update (only OFDA and OMLA)\n","                    if used_method == 2 or used_method == 3:\n","                        self.model.train()\n","                        with torch.no_grad(): # disable gradient computation for the forward pass\n","                            dispsf = self.model(img_pair, True) # execute forward pass to update running mean and variance of BatchNorm layer\n","                    \n","                    # online naive use train mode to avoid the usage of collected BN statistic\n","                    if used_method == 0:\n","                        self.model.train()\n","                    else:\n","                        self.model.eval()\n","\n","                    # get model output and self supervised loss\n","                    disps = self.model(img_pair, False) # use model to obtain disparities\n","                    loss = self.loss_function(disps, [left, right]) # calculate self-supervised loss from the images and the disparities\n","                    \n","                    # meta learning rate update (only Meta Learning and OMLA)\n","                    #if used_method == 1 or used_method == 3:\n","                        # update learning rate for each parameter with a gradient descent step\n","\n","                    # network weights update and evaluation\n","                    loss.backward() # calculate gradients updates with the self-supervised loss\n","                    self.optimizer.step() # update network parameters\n","                    \n","                    # evaluation on groundtruth depth only for frames in eigen_test split\n","                    for i,frame in enumerate (drive_frames[i:i+batch_size]):\n","                        if frame in self.dataset_dict[drive]:\n","                            if os.path.isfile(kitti_path + drive.rsplit('_', 3)[0] + '/' + drive + '/' + gt_path + '/' + frame):\n","                                eval_frame_disps(self.statistics, frame, kitti_path, drive, loss, disps, i)\n","                \n","                if show_logs:\n","                    print('├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤')\n","                sheet_string += logs_and_graphs(self.statistics, drive)\n","            \n","            if show_sheet_string:\n","                print()\n","                print('Copy and paste on Google Sheets (Ctrl+Shift+V to avoid style copy)')\n","                sheet_string = sheet_string.rsplit('\\n', 1)[0] # remove last crlf\n","                print(sheet_string)\n","\n","\n","def main():\n","    model = Model()\n","    model.perform_domain_adaptation()\n","\n","    \n","if __name__ == '__main__':\n","    main()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjdw25Dz5s5V","colab_type":"code","colab":{}},"source":["!zip -r results.zip results"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dGnVYGI5rgcK","colab_type":"text"},"source":["##**Extra**"]},{"cell_type":"code","metadata":{"id":"BFDjDvsRHCcA","colab_type":"code","colab":{}},"source":["# compute averages of performances for first 20 frames adabn on-off test\n","avg_statistics = [{'loss':     [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'rmse':     [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'log_rmse': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'abs_rel':  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'sq_rel':   [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'd1':       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'a1':       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'a2':       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n","                   'a3':       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}, 0]\n","\n","for day in os.listdir('results'):\n","    for drive in os.listdir('results/' + day):\n","        avg_statistics[1] += 1\n","        for file in os.listdir('results/' + day + '/' + drive):\n","            if file != 'graphs.png':\n","                with open('results/' + day + '/' + drive + '/' + file) as f:\n","                    for i,line in enumerate(f):\n","                        avg_statistics[0][file.split('_',1)[1].split('.')[0]][i] += float(line)\n","\n","avg_statistics[1] = avg_statistics[1] * 15\n","for i in range(15):\n","    for stat in avg_statistics[0]:\n","        print(i+5, stat, avg_statistics[0][stat][i]/avg_statistics[1])\n","    print()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"us3S2Q2Uuum2","colab_type":"code","colab":{}},"source":["#cholensky decomposition test\n","\n","mean = [2.5,1,0]\n","var = [0.5,0.2,1]\n","#emp_cov = np.cov()\n","emp_cov = [[4,12,-16],\n","           [12,37,-43],\n","           [-16,-43,98]]\n","print(emp_cov)\n","wb = np.linalg.cholesky(emp_cov)\n","print(wb)"],"execution_count":0,"outputs":[]}]}